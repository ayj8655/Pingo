## 인공지능(영상) 프로젝트

  * 이미지 파일
    - 용량이 큰 관계로 별도 링크를 통해 다운로드 후 datasets 폴더에 압축을 해제하여 사용합니다.
    - 다운로드: [https://drive.google.com/drive/folders/1_Md_iaLUsChAHEcm9bVDS9TfbTT7K8A_](https://drive.google.com/drive/folders/1_Md_iaLUsChAHEcm9bVDS9TfbTT7K8A_)


## 전체 진행 -> 1~5 완료
  
  

전처리 과정에서 데이터셋을 나누는 과정이 어려웠다. 이후 팀원들과 코드리뷰를 진행했는데 sklearn에 tarin_test_split이라는 메소드가 있어서 이후에는 저걸 사용해보면 좋겠다는 생각을 했다.


1. 단순 선형 회귀 모델 구현  
이미 구현되어있는 코드를 보며 이해하려고 노력하였다
   
2. 이미지 캡셔닝 Configuration  
   argparse에 대해 학습하고 필요하다고 생각되는 인자들을 생성하였다. 또한 utils.py에서 args를 받아 리턴하는 방식으로 저장하였다.

3.  이미지 캡셔닝 데이터 전처리
    1.  저장된 csv 파일을 읽어 이미지파일 이름과 캡션으로 나누어 2개의 리스트로 저장했다.
    2.  분리에서 어려움이 많았다. 전처리를 위해서는 이미지파일의 중복도 제거해야하고 그에맞게 캡션들이 인덱싱되어야했기때문에 리스트를 섞고 스플릿하였지만 중복을 제거하는 과정에서 반복문을 사용하였더니 속도가 너무 느렸다. 그래서 딕셔너리에 값을 넣어 중복을 제거하면서 순서를 유지했고 이를 리스트로 바꾼다음 다시 캡션들과 합쳐서 딕셔너리를 만들었다. 그 후 딕셔너리를 셔플하고 사이즈에 맞게 나누어 저장했다.
    3.  불러오기의 경우 3-1에서 진행한것을 인자에 따라 다르게 진행하는것으로 만들었다.
    4.  샘플링에대해 자세히 알지못했기에 데이터셋에서 일부를 가져오는 방식으로 진행하였다

4.  데이터 시각화    
   
    뽑힌 데이터셋에서 같은 인덱스의 값을 출력해서 구현하였다
     
     
5. Fashion MNIST    
   
    노드의 개수에 따른 손실과 정확도 차이
    순서대로 128, 512, 1024  
    전체적으로 노드의 개수가증가함에 따라 로스가 적어졌지만 테스트셋으로 예측해본 결과
    Epoch를 늘린다고 정확도가 크게 늘어나지는 않아서 다른 방법을 찾아봐야 할 것 같다.
    
  ```
  Epoch 1/5
  60000/60000 [==============================] - 3s 49us/sample - loss: 0.4989 - accuracy: 0.8244
  Epoch 2/5
  60000/60000 [==============================] - 3s 42us/sample - loss: 0.3760 - accuracy: 0.8645 
  Epoch 3/5 
  60000/60000 [==============================] - 3s 43us/sample - loss: 0.3384 - accuracy: 0.8770 
  Epoch 4/5 
  60000/60000 [==============================] - 2s 42us/sample - loss: 0.3161 - accuracy: 0.8852 
  Epoch 5/5 
  60000/60000 [==============================] - 2s 41us/sample - loss: 0.2956 - accuracy: 0.8897

  loss: 0.2860 - accuracy: 0.8654

  Epoch 1/5
  60000/60000 [==============================] - 3s 54us/sample - loss: 0.5035 - accuracy: 0.8232
  Epoch 2/5
  60000/60000 [==============================] - 3s 42us/sample - loss: 0.3735 - accuracy: 0.8645
  Epoch 3/5
  60000/60000 [==============================] - 3s 46us/sample - loss: 0.3364 - accuracy: 0.8773
  Epoch 4/5
  60000/60000 [==============================] - 3s 47us/sample - loss: 0.3115 - accuracy: 0.8849
  Epoch 5/5
  60000/60000 [==============================] - 5s 84us/sample - loss: 0.2939 - accuracy: 0.8914

  loss: 0.2539 - accuracy: 0.8826

  Epoch 1/5
  60000/60000 [==============================] - 3s 53us/sample - loss: 0.4704 - accuracy: 0.8324
  Epoch 2/5
  60000/60000 [==============================] - 3s 45us/sample - loss: 0.3593 - accuracy: 0.8686
  Epoch 3/5
  60000/60000 [==============================] - 3s 45us/sample - loss: 0.3225 - accuracy: 0.8806
  Epoch 4/5
  60000/60000 [==============================] - 3s 45us/sample - loss: 0.2981 - accuracy: 0.8897
  Epoch 5/5
  60000/60000 [==============================] - 3s 45us/sample - loss: 0.2798 - accuracy: 0.8979

  loss: 0.2144 - accuracy: 0.8776
  ```
  
  
  

